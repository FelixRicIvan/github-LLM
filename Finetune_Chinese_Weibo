! pip install transformers datasets
! pip install evaluate

!wget https://github.com/shhuangmust/AI/raw/refs/heads/113-1/weibo_senti_100k.csv

from datasets import load_dataset, DatasetDict

ds = load_dataset("csv", data_files="weibo_senti_100k.csv")
print(ds)

train_testvalid = ds['train'].train_test_split(test_size=0.2)
test_valid = train_testvalid['test'].train_test_split(test_size=0.5)
dataset = DatasetDict({
    'train': train_testvalid['train'],
    'test': test_valid['test'],
    'valid': test_valid['train']})

from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("google-bert/bert-base-chinese")

def tokenize_function(examples):
    return tokenizer(examples["review"], padding="max_length", truncation=True)

tokenized_datasets = dataset.map(tokenize_function, batched=True)

small_train_dataset = tokenized_datasets["train"].shuffle(seed=42).select(range(10000))
small_eval_dataset = tokenized_datasets["test"].shuffle(seed=42).select(range(10000))
print(small_train_dataset)
print(small_eval_dataset)

tokenized_datasets["train"][100]

from transformers import AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained("google-bert/bert-base-chinese", num_labels=2)

from transformers import TrainingArguments
import numpy as np
import evaluate

metric = evaluate.load("accuracy")
def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis=-1)
    return metric.compute(predictions=predictions, references=labels)

training_args = TrainingArguments(output_dir="test_trainer_chinese", evaluation_strategy="epoch")

from transformers import Trainer

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=small_train_dataset,
    eval_dataset=small_eval_dataset,
    compute_metrics=compute_metrics,
)
trainer.train()

from transformers import pipeline
pipe = pipeline("sentiment-analysis", model='test_trainer_chinese/checkpoint-1500', tokenizer=tokenizer)

pipe("我喜歡這個產品")


Epoch 	Training Loss 	Validation Loss 	Accuracy
1 	    0.157900 	      0.106620 	        0.980900
2 	    0.083800 	      0.072779 	        0.980900

Epoch 	Training Loss 	Validation Loss 	Accuracy
1 	    0.157900 	      0.106620 	        0.980900
2 	    0.083800 	      0.072779 	        0.980900
3 	    0.066700 	      0.067738 	        0.980700

TrainOutput(global_step=3750, training_loss=0.09955146840413412, metrics={'train_runtime': 3799.5831, 'train_samples_per_second': 7.896, 'train_steps_per_second': 0.987, 'total_flos': 7893331660800000.0, 'train_loss': 0.09955146840413412, 'epoch': 3.0})

[{'label': 'LABEL_1', 'score': 0.99994957447052}]
