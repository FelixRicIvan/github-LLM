
!pip install transformers

from transformers import AutoTokenizer, AutoModel
model=AutoModel.from_pretrained("bert-base-uncased");
print(model)

print(model.num_parameters())

from transformers import AutoTokenizer
tokenizer=AutoTokenizer.from_pretrained("bert-base-uncased")
raw_inputs = [
    "Hello my name is Felix",
    "I love this so much!",
]
inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors="pt")
print(inputs)

###
input im using :
"Hello my name is Felix",
"I love this so much!"

token:
{'input_ids': tensor([[ 101, 7592, 2026, 2171, 2003, 8383,  102,    0],
        [ 101, 1045, 2293, 2023, 2061, 2172,  999,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0],
        [1, 1, 1, 1, 1, 1, 1, 1]])}
###
